<!DOCTYPE html>
<html lang="en-US">
<head>
<meta charset="UTF-8" />
<title>Artificial Intelligence</title>
</head>
<body >
    <A HREF="fifthPage.html">page 5</A>
<div style='padding-bottom:10px;' class='av-special-heading av-special-heading-h2  blockquote modern-quote  avia-builder-el-14  el_after_av_textblock  el_before_av_textblock  '><h2 class='av-special-heading-tag' itemprop="headline">The Top Myths About Advanced AI</h2><div class='special-heading-border'><div class='special-heading-inner-border'></div></div></div>
<section class="av_textblock_section" itemscope="itemscope" itemtype="https://schema.org/CreativeWork"><div class='avia_textblock ' itemprop="text"><p>A captivating conversation is taking place about the future of artificial intelligence and what it will/should mean for humanity. There are fascinating controversies where the world&#8217;s leading experts disagree, such as: AI&#8217;s future impact on the job market; if/when human-level AI will be developed; whether this will lead to an intelligence explosion; and whether this is something we should welcome or fear. But there are also many examples of of boring pseudo-controversies caused by people misunderstanding and talking past each other. To help ourselves focus on the interesting controversies and open questions &#8212; and not on the misunderstandings &#8212; let&#8217;s  clear up some of the most common myths.</p>
</div></section>
<div class="flex_column av_one_full  flex_column_div av-zero-column-padding first  avia-builder-el-16  el_after_av_textblock  el_before_av_heading  column-top-margin" style='border-radius:0px; '><div class='avia-image-container  av-styling-   avia-builder-el-17  avia-builder-el-no-sibling  avia-align-center ' itemscope="itemscope" itemtype="https://schema.org/ImageObject"><div class='avia-image-container-inner'><img class='avia_image ' src='https://futureoflife.org/wp-content/uploads/2016/08/myths-1.jpg?x59035' alt='AI myths' title='Print' itemprop="contentURL" /></div></div></div>
<div style='padding-bottom:10px;' class='av-special-heading av-special-heading-h2  blockquote modern-quote  avia-builder-el-18  el_after_av_one_full  el_before_av_textblock  '><h2 class='av-special-heading-tag' itemprop="headline">Timeline Myths</h2><div class='special-heading-border'><div class='special-heading-inner-border'></div></div></div>
<section class="av_textblock_section" itemscope="itemscope" itemtype="https://schema.org/CreativeWork"><div class='avia_textblock ' itemprop="text"><p>The first myth regards the timeline: how long will it take until machines greatly supersede human-level intelligence? A common misconception is that we know the answer with great certainty.</p>
<p>One popular myth is that we know we&#8217;ll get superhuman AI this century. In fact, history is full of technological over-hyping. Where are those fusion power plants and flying cars we were promised we&#8217;d have by now? AI has also been repeatedly over-hyped in the past, even by some of the founders of the field. For example, John McCarthy (who coined the term &#8220;artificial intelligence&#8221;), Marvin Minsky, Nathaniel Rochester and Claude Shannon wrote this overly optimistic forecast about what could be accomplished during two months with stone-age computers: <em>&#8220;We propose that a 2 month, 10 man study of artificial intelligence be carried out during the summer of 1956 at Dartmouth College [&#8230;]</em> <em>An attempt will be made to find how to make machines use language, form abstractions and concepts, solve kinds of problems now reserved for humans, and improve themselves. We think that a significant advance can be made in one or more of these problems if a carefully selected group of scientists work on it together for a summer.&#8221;</em></p>
<p>On the other hand, a popular counter-myth is that we know we won&#8217;t get superhuman AI this century. Researchers have made a wide range of estimates for how far we are from superhuman AI, but we certainly can&#8217;t say with great confidence that the probability is zero this century, given the dismal track record of such techno-skeptic predictions. For example, Ernest Rutherford, arguably the greatest nuclear physicist of his time, said in 1933 &#8212; less than 24 hours before Szilard&#8217;s invention of the nuclear chain reaction &#8212; that nuclear energy was &#8220;moonshine.&#8221; And Astronomer Royal Richard Woolley called interplanetary travel &#8220;utter bilge&#8221; in 1956. The most extreme form of this myth is that superhuman AI will never arrive because it&#8217;s physically impossible. However, physicists know that a brain consists of quarks and electrons arranged to act as a powerful computer, and that there&#8217;s no law of physics preventing us from building even more intelligent quark blobs.</p>
<p>There have been a number of surveys asking AI researchers how many years from now they think we&#8217;ll have human-level AI with at least 50% probability. All these surveys have the same conclusion: the world&#8217;s leading experts disagree, so we simply don&#8217;t know. For example, in such a poll of the AI researchers at the >2015 Puerto Rico AI conference, the average (median) answer was by year 2045, but some researchers guessed hundreds of years or more.</p>
<p>There&#8217;s also a related myth that people who worry about AI think it&#8217;s only a few years away. In fact, most people on record worrying about superhuman AI guess it&#8217;s still at least decades away. But they argue that as long as we&#8217;re not 100% sure that it won&#8217;t happen this century, it&#8217;s smart to start safety research now to prepare for the eventuality. Many of the safety problems associated with human-level AI are so hard that they may take decades to solve. So it&#8217;s prudent to start researching them now rather than the night before some programmers drinking Red Bull decide to switch one on.</p>
</div></section>
<div style='padding-bottom:10px;' class='av-special-heading av-special-heading-h2  blockquote modern-quote  avia-builder-el-20  el_after_av_textblock  el_before_av_textblock  '><h2 class='av-special-heading-tag' itemprop="headline">Controversy Myths</h2><div class='special-heading-border'><div class='special-heading-inner-border'></div></div></div>
<section class="av_textblock_section" itemscope="itemscope" itemtype="https://schema.org/CreativeWork"><div class='avia_textblock ' itemprop="text"><p>Another common misconception is that the only people harboring concerns about AI and advocating AI safety research are luddites who don&#8217;t know much about AI. When Stuart Russell, author of the standard AI textbook, mentioned this during his Puerto Rico talk, the audience laughed loudly. A related misconception is that supporting AI safety research is hugely controversial. In fact, to support a modest investment in AI safety research, people don&#8217;t need to be convinced that risks are high, merely non-negligible &#8212; just as a modest investment in home insurance is justified by a non-negligible probability of the home burning down.</p>
<p>It may be that media have made the AI safety debate seem more controversial than it really is. After all, fear sells, and articles using out-of-context quotes to proclaim imminent doom can generate more clicks than nuanced and balanced ones. As a result, two people who only know about each other&#8217;s positions from media quotes are likely to think they disagree more than they really do. For example, a techno-skeptic who only read about Bill Gates&#8217;s position in a British tabloid may mistakenly think Gates believes superintelligence to be imminent. Similarly, someone in the beneficial-AI movement who knows nothing about Andrew Ng&#8217;s position except his quote about overpopulation on Mars may mistakenly think he doesn&#8217;t care about AI safety, whereas in fact, he does. The crux is simply that because Ng&#8217;s timeline estimates are longer, he naturally tends to prioritize short-term AI challenges over long-term ones.</p>
</div></section>
</body>
</html>
