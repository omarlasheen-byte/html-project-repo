<!DOCTYPE html>
<html lang="en-US">
<head>
<meta charset="UTF-8" />
<title>Artificial Intelligence</title>
</head>
<body >
    
<div style='padding-bottom:10px;' class='av-special-heading av-special-heading-h2  blockquote modern-quote  avia-builder-el-22  el_after_av_textblock  el_before_av_textblock  '><h2 class='av-special-heading-tag' itemprop="headline">Myths About the Risks of Superhuman AI</h2><div class='special-heading-border'><div class='special-heading-inner-border'></div></div></div>
<section class="av_textblock_section" itemscope="itemscope" itemtype="https://schema.org/CreativeWork"><div class='avia_textblock ' itemprop="text"><p>Many AI researchers roll their eyes when seeing this headline Stephen Hawking warns that rise of robots may be disastrous for mankind.&#8221; </em>And as many have lost count of how many similar articles they&#8217;ve seen. Typically, these articles are accompanied by an evil-looking robot carrying a weapon, and they suggest we should worry about robots rising up and killing us because they&#8217;ve become conscious and/or evil. On a lighter note, such articles are actually rather impressive, because they succinctly summarize the scenario that AI researchers <em>don&#8217;t</em> worry about. That scenario combines as many as three separate misconceptions: concern about <em>consciousness</em>, <em>evil,</em> and <em>robots</em>.</p>
<p>If you drive down the road, you have a subjective experience of colors, sounds, <em>etc</em>. But does a self-driving car have a subjective experience? Does it feel like anything at all to be a self-driving car? Although this mystery of consciousness is interesting in its own right, it&#8217;s irrelevant to AI risk. If you get struck by a driverless car, it makes no difference to you whether it subjectively feels conscious. In the same way, what will affect us humans is what superintelligent AI <em>does</em>, not how it subjectively <em>feels</em>.</p>
<p>The fear of machines turning evil is another red herring. The real worry isn&#8217;t malevolence, but competence. A superintelligent AI is by definition very good at attaining its goals, whatever they may be, so we need to ensure that its goals are aligned with ours. Humans don&#8217;t generally hate ants, but we&#8217;re more intelligent than they are – so if we want to build a hydroelectric dam and there&#8217;s an anthill there, too bad for the ants. The beneficial-AI movement wants to avoid placing humanity in the position of those ants.</p>
<p>The consciousness misconception is related to the myth that machines can&#8217;t have goals. Machines can obviously have goals in the narrow sense of exhibiting goal-oriented behavior: the behavior of a heat-seeking missile is most economically explained as a goal to hit a target. If you feel threatened by a machine whose goals are misaligned with yours, then it is precisely its goals in this narrow sense that troubles you, not whether the machine is conscious and experiences a sense of purpose. If that heat-seeking missile were chasing you, you probably wouldn&#8217;t exclaim: <em>&#8220;I&#8217;m not worried, because machines can&#8217;t have goals!&#8221;</em></p>
<p>I sympathize with Rodney Brooks and other robotics pioneers who feel unfairly demonized by scaremongering tabloids, because some journalists seem obsessively fixated on robots and adorn many of their articles with evil-looking metal monsters with red shiny eyes. In fact, the main concern of the beneficial-AI movement isn&#8217;t with robots but with intelligence itself: specifically, intelligence whose goals are misaligned with ours. To cause us trouble, such misaligned superhuman intelligence needs no robotic body, merely an internet connection – this may enable outsmarting financial markets, out-inventing human researchers, out-manipulating human leaders, and developing weapons we cannot even understand. Even if building robots were physically impossible, a super-intelligent and super-wealthy AI could easily pay or manipulate many humans to unwittingly do its bidding.</p>
<p>The robot misconception is related to the myth that machines can&#8217;t control humans. Intelligence enables control: humans control tigers not because we are stronger, but because we are smarter. This means that if we cede our position as smartest on our planet, it&#8217;s possible that we might also cede control.</p>
</div></section>
<div style='padding-bottom:10px;' class='av-special-heading av-special-heading-h2  blockquote modern-quote  avia-builder-el-24  el_after_av_textblock  el_before_av_textblock  '><h2 class='av-special-heading-tag' itemprop="headline">The Interesting Controversies</h2><div class='special-heading-border'><div class='special-heading-inner-border'></div></div></div>
<section class="av_textblock_section" itemscope="itemscope" itemtype="https://schema.org/CreativeWork"><div class='avia_textblock ' itemprop="text"><p>Not wasting time on the above-mentioned misconceptions lets us focus on true and interesting controversies where even the experts disagree. What sort of future do you want? Should we develop lethal autonomous weapons? What would you like to happen with job automation? What career advice would you give today&#8217;s kids? Do you prefer new jobs replacing the old ones, or a jobless society where everyone enjoys a life of leisure and machine-produced wealth? Further down the road, would you like us to create superintelligent life and spread it through our cosmos? Will we control intelligent machines or will they control us? Will intelligent machines replace us, coexist with us, or merge with us? What will it mean to be human in the age of artificial intelligence? What would you like it to mean, and how can we make the future be that way? Please join the conversation!</p>
</div></section>
<div class="flex_column av_one_full  flex_column_div av-zero-column-padding first  avia-builder-el-26  el_after_av_textblock  el_before_av_comments_list  column-top-margin" style='border-radius:0px; '><div style='padding-bottom:10px;' class='av-special-heading av-special-heading-h2  blockquote modern-quote  avia-builder-el-27  el_before_av_textblock  avia-builder-el-first  '><h2 class='av-special-heading-tag' itemprop="headline">Recommended References</h2><div class='special-heading-border'><div class='special-heading-inner-border'></div></div></div>
<p><span class="header">Books</span></p>
<ul>
<li><strong><a href="http://www.amazon.com/gp/product/0199678111/">Superintelligence: Paths, Dangers, Strategies </a></strong></li>
<li><a href="https://www.amazon.com/Life-3-0-Being-Artificial-Intelligence/dp/1101946598">Life 3.0: Being Human in the Age of Artificial Intelligence</a></li>
<li><a href="http://www.amazon.com/Our-Final-Invention-Artificial-Intelligence/dp/0312622376/ref=pd_sim_b_4?ie=UTF8&amp;refRID=0HRBX1Z9YQA480PKPN41">Our Final Invention: Artificial Intelligence and the End of the Human Era</a></li>
<li><a href="http://intelligenceexplosion.com/">Facing the Intelligence Explosion</a></li>
<li><a href="https://intelligence.org/smarter-than-us/">E-book about the AI risk</a> (including a &#8220;Terminator&#8221; scenario that&#8217;s more plausible than the movie version)</li>
</ul>

<p>Many of the organizations listed on this page and their descriptions are from a list compiled by the Global Catastrophic Risk institute; we are most grateful for the efforts that they have put into compiling it. These organizations above all work on computer technology issues, though many cover other topics as well. This list is undoubtedly incomplete; please contact us to suggest additions or corrections.</p>

</body>
</html>
